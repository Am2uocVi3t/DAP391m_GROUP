import numpy as np 
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

url = "vietnam_63provinces_ALL_VARS_weather_sample_20250531_20250607.csv"
df = pd.read_csv(url)
df.head()


print(df.dtypes)
print(df.describe())
print(df.nunique())
for col in df.columns:
    print("Col: ", col)
    print(df[col].unique())


df.isnull().sum()


for col in df.columns:
    print(df.nunique())


df = df.dropna()
df['is_hot_day'] = (df['temperature_2m'] > 25).astype(int)

print(df["is_hot_day"].value_counts())


corr_matrix = df.corr(numeric_only=True)
corr_temp = corr_matrix["temperature_2m"].drop("temperature_2m").sort_values(ascending=False)

high_corr_features = corr_temp[abs(corr_temp) > 0.5]
print(high_corr_features)


from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

df = df.dropna()
selected_features = list(set(high_corr_features.index.tolist()))
if "is_hot_day" in selected_features:
    selected_features.remove("is_hot_day")
    

df_classification = df[selected_features + ["is_hot_day"]].dropna()

X_cls = df_classification[selected_features]
y_cls = df_classification["is_hot_day"]

scaler = StandardScaler()
X_cls_scaled = scaler.fit_transform(X_cls)


X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(
    X_cls_scaled, y_cls, test_size=0.3, random_state=42
)

classification_models = {
    "LogisticRegression": LogisticRegression(max_iter=1000),
    "RandomForest": RandomForestClassifier(random_state=42),
    "GradientBoosting": GradientBoostingClassifier(random_state=42),
    "DecisionTree": DecisionTreeClassifier(random_state=42),
    "SVC": SVC()
}

cls_results = []

for name, model in classification_models.items():
    model.fit(X_train_cls, y_train_cls)
    y_pred = model.predict(X_test_cls)
    acc = accuracy_score(y_test_cls, y_pred)
    prec = precision_score(y_test_cls, y_pred, zero_division=0)
    rec = recall_score(y_test_cls, y_pred)
    f1 = f1_score(y_test_cls, y_pred)
    cls_results.append((name, acc, prec, rec, f1))

cls_results_df = pd.DataFrame(cls_results, columns=["Model", "Accuracy", "Precision", "Recall", "F1 Score"])
cls_results_df.sort_values(by="F1 Score", ascending=False, inplace=True)
cls_results_df.reset_index(drop=True, inplace=True)
cls_results_df


for name, model in classification_models.items():
    model.fit(X_train_cls, y_train_cls)
    y_pred = model.predict(X_test_cls)
    cm = confusion_matrix(y_test_cls, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot()
    plt.title(f"Confusion Matrix: {name}")
    plt.show()


from sklearn.metrics import roc_auc_score, roc_curve

plt.figure(figsize=(10, 7))

for name, model in classification_models.items():
    if hasattr(model, "predict_proba"):
        y_score = model.predict_proba(X_test_cls)[:, 1]
    else:
        if hasattr(model, "decision_function"):
            y_score = model.decision_function(X_test_cls)
        else:
            continue
    fpr, tpr, _ = roc_curve(y_test_cls, y_score)
    auc = roc_auc_score(y_test_cls, y_score)

    plt.plot(fpr, tpr, label=f"{name} (AUC = {auc:.2f})")

plt.plot([0, 1], [0, 1], "k--", label="Random (AUC = 0.5)")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - AUC Score")
plt.legend(loc="lower right")
plt.grid(True)
plt.show()



